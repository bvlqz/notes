{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c2d899-95e1-401b-8407-cd40996fbf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06082321-d076-4dc8-8f8d-5e203e41d1c6",
   "metadata": {},
   "source": [
    "### Fetch Data\n",
    "California Housing Prices dataset from the StatLib repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806bb2b7-7728-42f0-b832-760e90dd5317",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataUrl = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.tgz\"\n",
    "\n",
    "dataTgzPath = Path(\"housing.tgz\")\n",
    "dataCsvPath = Path(\"housing.csv\")\n",
    "\n",
    "if not dataCsvPath.exists():\n",
    "    urllib.request.urlretrieve(dataUrl, dataTgzPath)\n",
    "    dataTgzFile = tarfile.open(dataTgzPath)\n",
    "    dataTgzFile.extractall()\n",
    "    dataTgzFile.close()\n",
    "    dataTgzPath.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b2b1be-77a8-47c5-bf64-9d6f297336f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "housingData = pd.read_csv(dataCsvPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdf79ef-ea09-4752-9f09-8b5380772db9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "###### Show the first 5 rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76fad61-08ac-4075-9861-01438ca65c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housingData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68631b10-2ec6-4da2-bc0c-4c78982e2230",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "###### Show column names and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe371dbe-ffe6-4050-9175-cd7e42b21e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "housingData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4338df24-ca4b-4132-b7eb-a267ab274d07",
   "metadata": {},
   "source": [
    "Notice ```total_bedrooms``` has only 20433 nonnull values, meaning 207 districts are missing that feature\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e1cacb-998a-4fea-b4b8-2fe4c0f29f04",
   "metadata": {},
   "source": [
    "###### Show column count, mean, std, min, max, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6892d9a-998f-4840-a2ed-a95c4e2a317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "housingData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a83349-c744-4d89-a4b7-ef9307d7ef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "housingData.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8f3f25-2a27-4fea-96fe-4738351c0b91",
   "metadata": {},
   "source": [
    "Some of these histograms are tail-heavy, they extend much farther to the right of the median. This may make it harder for some ML algorithms to detect patterns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a3d7b0-c6cb-49fe-8259-c552f7c66236",
   "metadata": {},
   "outputs": [],
   "source": [
    "housingData[\"median_income\"].hist(bins=50, figsize=(15,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ab951a-8f6e-4322-802c-d47446aed954",
   "metadata": {},
   "source": [
    "The data has been scaled and capped at 15\n",
    "\n",
    "15  - Higher Median Incomes\n",
    "\n",
    "0.5 - Lower Median Incomes\n",
    "\n",
    "This number also represents rought tens of thousands of dollars (eg. 3 is about $30,000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f13bdf5-bb9a-4607-84cb-4a5ac92532f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "housingData[[\"housing_median_age\", \"median_house_value\"]].hist(figsize=(15,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2655c1-e446-4dc2-a376-07c8e86a3bd6",
   "metadata": {},
   "source": [
    "Both of these attributes are capped, meaning you can collect propper labels or you can remove capped districts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed4f56f-f1a8-4bf3-821b-0bbb6b07422b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Find correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c985637-2839-4df6-95d7-785dbf5dd1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(housingData, figsize=(25, 15))\n",
    "housingData.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2dcaef-3db8-4d65-887e-e8ec32a9d043",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bf1fca-a892-434b-9be2-55229088fb28",
   "metadata": {},
   "source": [
    "#### Missing Features\n",
    "\n",
    "Since ```total_bedrooms``` is missing 207 values, the options are\n",
    "1. Get rid of the corresponding districts:\n",
    "\n",
    "```python\n",
    "housingData.dropna(subset[\"total_bedrooms\"])\n",
    "```\n",
    "2. Get rid of the whole attribute:\n",
    "\n",
    "```python\n",
    "housingData.drop(subset[\"total_bedrooms\"], axis=1)\n",
    "```\n",
    "3. Set the values to some value:\n",
    "\n",
    "```python\n",
    "median = housingData[\"total_bedrooms\"].median()\n",
    "housingData[\"total_bedrooms\"].fillna(median, inplace=True)\n",
    "```\n",
    "\n",
    "or use `sklearn.impute.SimpleImputer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338926c2-0ac3-4fd0-b3ac-72d9a2686b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "inputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "# ocean_proximty contains only text attributes\n",
    "# create another dataframe based on the original\n",
    "# with only numerical attributes\n",
    "\n",
    "housingDataNumericalOnly = housingData.drop(\"ocean_proximity\", axis=1)\n",
    "\n",
    "# This will apply the inputer to all missing numerical\n",
    "# values, not only ocean_proximity\n",
    "inputer.fit(housingDataNumericalOnly)\n",
    "print(inputer.statistics_)\n",
    "\n",
    "transformedFeatures = inputer.transform(housingDataNumericalOnly)\n",
    "\n",
    "# Put back into pandas dataframe\n",
    "housingDataFull = pd.DataFrame(transformedFeatures, \n",
    "                           columns=housingDataNumericalOnly.columns, \n",
    "                           index=housingDataNumericalOnly.index)\n",
    "\n",
    "housingDataFull.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850c8145-1702-44a4-87ff-a0415d3a5cba",
   "metadata": {},
   "source": [
    "#### Text and Categorial Attributes\n",
    "```ocean_proximity``` contains text attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d022a18-db56-4201-b2d0-749fd2093965",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housingData[\"ocean_proximity\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798ac92b-bce7-4b71-9a6f-a105df502a6f",
   "metadata": {},
   "source": [
    "There are a limited number of possible values, each of one represents a category. So this attribute is a categorial attribute.\n",
    "\n",
    "```sklearn.preprocessing.OrdinalEncoder``` can convert text to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506bf013-a7ea-4a1c-b4bf-3fa5c4c7f7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordEnc = OrdinalEncoder()\n",
    "housingDataEncoded = ordEnc.fit_transform(housingData[[\"ocean_proximity\"]])\n",
    "np.unique(housingDataEncoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af2ea8b-f215-42ae-bb31-b173aaf22dc4",
   "metadata": {},
   "source": [
    "This can create a problem, some ML algorithms will assume that two nearby values are more similar than two distant values. This may be fine in some cases (e.g. some ordered categories lokes \"bad\", \"average\", \"good\" and \"excelent\"), but it is not the case here. To fix this issue, a common solution is to create one binary attribute per category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c3078d-1b02-4a18-a4d1-c77aa552d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "categoriesEncoder = OneHotEncoder()\n",
    "housingCategories1H = categoriesEncoder.fit_transform(housingData[[\"ocean_proximity\"]])\n",
    "housingCategories1H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b145c8ef-6d93-4c14-a623-ff30f441f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(categoriesEncoder.categories_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ed1134-3573-46df-ac18-e20bd14341b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housingCategories1H[0, :].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05b503f-cf89-4596-901c-eca7db6791b5",
   "metadata": {},
   "source": [
    "#### Custom Transformers\n",
    "It is a good idea to try attribute combinations:\n",
    "\n",
    "```python\n",
    "housingData[\"rooms_per_household\"] = housingData[\"total_rooms\"] / housingData[\"households\"] \n",
    "housingData[\"bedrooms_per_room\"] = housingData[\"total_bedrooms\"] / housingData[\"total_rooms\"] \n",
    "housingData[\"population_per_household\"] = housingData[\"population\"] / housingData[\"households\"] \n",
    "```\n",
    "\n",
    "The following class is a Custom Transformer that adds attributes combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70da16f7-a117-4ea3-96aa-3dcde15768e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# column index\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room=True): # no *args or **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,\n",
    "                         bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "# Create a class to select numerical or categorical columns \n",
    "class OldDataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2749abfe-5917-4c83-a53a-ca71885029ed",
   "metadata": {},
   "source": [
    "#### Feature Scaling\n",
    "ML algorithms don't perform well when the input numerical attributes have very different scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2267afc-5b35-4a92-95b2-2a9c0fdafe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# Create a train set and a test set, the test set is usually 20% of the data\n",
    "HousingDataTrainSet, housingDataTestSet = train_test_split(housingData, test_size=0.2, random_state=42)\n",
    "\n",
    "HousingDataTrainSetToFit = HousingDataTrainSet.drop(\"median_house_value\", axis=1)\n",
    "HousingDataTrainSetLabels = HousingDataTrainSet[\"median_house_value\"].copy()\n",
    "\n",
    "housingDataNumericalOnly = HousingDataTrainSetToFit.drop(\"ocean_proximity\", axis=1)\n",
    "\n",
    "numericalAttributes = list(housingDataNumericalOnly)\n",
    "categoricalAttributes = [\"ocean_proximity\"]\n",
    "\n",
    "numericalPipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('attributes_adder', CombinedAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "fullPipeline = ColumnTransformer([\n",
    "    ('numerical', numericalPipeline, numericalAttributes),\n",
    "    ('categorical', OneHotEncoder(), categoricalAttributes)\n",
    "])\n",
    "\n",
    "preparedHousingData = fullPipeline.fit_transform(HousingDataTrainSetToFit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a2f1f3-5285-4e4c-a4d7-1409fd0d27ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "preparedHousingData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fe81da-65b7-4c2e-8af6-e6ad3789a748",
   "metadata": {},
   "outputs": [],
   "source": [
    "preparedHousingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5f83dd-a0c0-4d43-84b8-2d2f70e589bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linReg = LinearRegression()\n",
    "linReg.fit(preparedHousingData, HousingDataTrainSetLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75b10d6-20bd-44d7-af41-4c9a793952ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try the full preprocessing pipeline on a few training instances\n",
    "some_data = HousingDataTrainSetToFit.iloc[:5]\n",
    "some_labels = HousingDataTrainSetLabels.iloc[:5]\n",
    "some_data_prepared = fullPipeline.transform(some_data)\n",
    "\n",
    "print(\"Predictions:\", linReg.predict(some_data_prepared))\n",
    "plt.plot(linReg.predict(some_data_prepared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d21baed-648e-4e2e-8a87-b7bee3d34dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Labels:\", list(some_labels))\n",
    "plt.plot(list(some_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480aa6e0-acbc-407c-8ae5-5b236c4244aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "housing_predictions = lin_reg.predict(housing_prepared)\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f876d432-f739-4503-8ab0-6aa597bb8962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
